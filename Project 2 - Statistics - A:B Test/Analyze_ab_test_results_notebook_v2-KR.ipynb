{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze A/B Test Results \n",
    "\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Conclusions](#conclusions)\n",
    "- [Submission](#submission)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "이 프로젝트에서는 이커머스 웹사이트의 A/B 테스트의 결과를 이해하기 위해 데이터 분석 과정을 진행할 것이다.     \n",
    "이 노트북을 통해서 회사가 아래 선택지 중 어떤 선택을 해야할지 알아보자. \n",
    "- 새로운 웹페이지를 시행, \n",
    "- 기존 웹페이지를 유지,\n",
    "- 결정을 내리기 위해 더 오래 실험을 진행 \n",
    "\n",
    "<a id='probability'></a>\n",
    "## Part I - Probability\n",
    "\n",
    "먼저, 라이브러리를 import 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#setting the seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "이제 `ab_data.csv` 데이터를 읽어와 `df`에 저장할 것이다. 아래 표는 데이터를 설명한 것으로, 총 5개의 컬럼이 있다. \n",
    " \n",
    " \n",
    "<center>\n",
    "\n",
    "|컬럼|목적|유효값|\n",
    "| ------------- |:-------------| -----:|\n",
    "|user_id|사용자 ID의 고유값|Int64 values|\n",
    "|timestamp|사용자가 웹페이지를 방문한 시각|-|\n",
    "|group|이 A/B 테스트에서, 사용자는 두개의 큰 그룹으로 나눠져있다.<br> `control` 그룹 사용자에게는 `old_page`가 보여지고, `treatment` 그룹 사용자에게는 `new_page`가 보여지게 된다. <br>그러나, 원본 데이터에는 `control` 그룹 사용자인데 `new_page` 가 보여지는 등 **일부 부정확한 데이터** 가 존재한다.|`['control', 'treatment']`|\n",
    "|landing_page|사용자가 방문한 페이지를 나타낸다.|`['old_page', 'new_page']`|\n",
    "|converted|사용자가 최종적으로 회사의 상품을 구매하였는지 여부를 나타낸다. 여기서, `1`은 그 사용자가 상품을 구매했다는 것을 의미한다.|`[0, 1]`|\n",
    "</center>\n",
    "\n",
    "**a.** `ab_data.csv` 파일에서 데이터셋을 읽어와 몇 개의 행을 살펴보자:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 읽어오기\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** 데이터셋의 총 행 개수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행개수\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** 고유한 사용자 수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유한 사용자 수\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**d.** 전환한 사용자의 비율."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전환한 사용자의 비율\n",
    "df['converted'].sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**e.** \"group\"이 `treatment`인데 \"landing_page\"가 `new_page`가 아닌 경우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1965"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"group\"이 treatment인데 \"landing_page\"가 new_page가 아닌 경우의 수\n",
    "df.query('group == \"treatment\" and landing_page != \"new_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"group\"이 control인데 \"landing_page\"가 old_page가 아닌 경우의 수\n",
    "df.query('group == \"control\" and landing_page != \"old_page\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 두 숫자의 합\n",
    "df.query('group == \"treatment\" and landing_page != \"new_page\"').shape[0] + df.query('group == \"control\" and landing_page != \"old_page\"').shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f.** 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "df.isnull().sum() # 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  \n",
    "**group** 과 **landing_page** 컬럼은 아래 둘 중 하나의 값을 가져야 한다:\n",
    "\n",
    "|user_id| timestamp|group|landing_page|converted|\n",
    "|---|---|---|---|---|\n",
    "|XXXX|XXXX|`control`| `old_page`|X |\n",
    "|XXXX|XXXX|`treatment`|`new_page`|X |\n",
    "\n",
    "\n",
    "즉, `control`그룹 사용자는 `old_page`와, `treatment`그룹 사용자는 `new_page`와 매치가 되어야 한다. \n",
    "\n",
    "그러나, 몇 개의 행에서 `treatment`그룹인데도 `new_page` 값이 있거나, `control`그룹인데 `old_page` 값이 있는데, 이 경우 우리는 실제 사용자가 어떤 페이지를 받았는지 확신할 수 없다.   \n",
    "\n",
    "**a.** 부정확한 행들을 삭제하고, 그 결과를 새로운 데이터프레임 **df2**에 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부정확한 행들을 삭제하고, 그 결과를 새로운 데이터프레임 df2에 저장.\n",
    "df2 = df.drop(df[((df['group']=='treatment') & (df['landing_page']=='old_page') | (df['group']=='control') & (df['landing_page']=='new_page'))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 부정확한 행들이 df2에서 삭제되었는지 재 확인 - \n",
    "# 아래 구문의 결과값은 0이어야 함. \n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  \n",
    "**df2** 와 아래 셀들을 통해 질문에 답해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** **df2**에는 고유한 **user_id**가 몇 개 있는지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 고유한 user_id 개수\n",
    "df2.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**b.** **df2**에는 중복된 **user_id**가 1개 있다. 어떤 것인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 user_id 찾기\n",
    "df2[df2.duplicated(['user_id'])].user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** 중복된 **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 동일한 user_id를 가진 중복된 행\n",
    "df2[df2.duplicated(['user_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** **df2**에서 중복된 **user_id**를 가진 행 중 하나를 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2에서 중복된 user_id를 가진 행 중 하나를 삭제한다.\n",
    "# 주의! 중복된 user_id를 가진 행이 완전히 똑같은 값을 가지고 있는게 아니기 때문에 dataframe.drop_duplicates()는 적용안됨. \n",
    "df2 = df2.drop_duplicates(subset=\"user_id\", keep=\"first\")\n",
    "\n",
    "# 삭제되었는지 재 확인\n",
    "df2[df2.duplicated(['user_id'])].shape[0]  # 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.4  \n",
    "**df2** 와 아래 셀들을 통해 질문에 답해보자.\n",
    "\n",
    "**a.** 받은 페이지에 관계없이 사용자의 전환율 얼마인가?<br><br>\n",
    "> 확률은 전체 사용자 중 \"전환된\" 성공률이며, $p_{population}$ 로 표현된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 사용자의 전환율\n",
    "df2.converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** 사용자가 `control` 그룹이라고 할 때, 전환율은 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/f7xfvbxd1p3470n641kdm7l00000gn/T/ipykernel_17158/2362478500.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  conv_rate_c = df2[df['group']=='control'].converted.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"control\" 그룹에서 사용자의 전환율\n",
    "conv_rate_c = df2[df['group']=='control'].converted.mean()\n",
    "conv_rate_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** 사용자가  `treatment` 그룹이라고 할 때, 전환율은 얼마인가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/f7xfvbxd1p3470n641kdm7l00000gn/T/ipykernel_17158/1699139085.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  conv_rate_t = df2[df['group']=='treatment'].converted.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"treatment\" 그룹에서 사용자의 전환율\n",
    "conv_rate_t = df2[df['group']=='treatment'].converted.mean()\n",
    "conv_rate_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위 (b)와 (c)에서 구한 확률은 전환율로 표현할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 두 그룹의 전환율의 차이(obs_diff)를 계산.\n",
    "obs_diff = conv_rate_t - conv_rate_c\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** 사용자가 new page를 받을 확률은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자가 \"new page\"를 받을 확률\n",
    "df2[df2['landing_page']=='new_page'].shape[0] / df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오래된 페이지를 받은 `control` 그룹과 새로운 페이지를 받은 `treatment` 그룹간의 전환율 차이는 **0.0015**로 매우 **근소한** 차이로 보인다.    \n",
    "따라서 새로운 페이지를 받은 `treatment` 그룹의 사용자가 더 많은 전환을 했다고 말하기는 어렵다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "## Part II - A/B Test\n",
    "\n",
    "timestamp 는 각 이벤트와 연계되기 때문에, 우리가 이벤트들을 인지할 수 있는 한 우리는 계속해서 가설 검정을 진행할 수 있다. \n",
    "\n",
    "그러나, 어려운 문제는: \n",
    "- 한 페이지가 다른 페이지보다 유의미하게 더 낫다고 여겨지는 즉시 멈출 것인가? 아니면 이것이 특정 기간동안 계속해서 일어나야 하는가? \n",
    "- 어떤 한 페이지가 다른 페이지보다 낫다는 결정을 하기 위해서는 얼마나 오래 실험을 해야하는가? \n",
    "\n",
    "이런 질문들은 보통 A/B 테스트를 할 때 고려해야하는 어려운 부분들이다. \n",
    "\n",
    "\n",
    "### 2.1\n",
    "지금은, 단지 주어진 데이터에만 근거해서 결정을 내려야 한다고 가정해보자.   \n",
    "\n",
    "> 앞서 전환율을 계산했을 때, old page 가 new page보다 전환율이 **근소하게** 높았던 것을 기억해보자 (1.4.c).\n",
    "\n",
    "만약 제 1종 오류율을 5%로 가정했을 때 new page가 확실히 더 낫지 않은 이상, old page가 new page 보다 더 낫다고 가정하고자 할때,   \n",
    "귀무가설과 대립가설(**$H_0$** and **$H_1$**)은 각각 어떻게 될까?  \n",
    "\n",
    "이 가정을 말로 풀어서 또는 용어로 설명하자면, old page와 new page의 \"전환\" 확률 (혹은 비율) 또는 **$p_{old}$** and **$p_{new}$** 라고 할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- **$H_0$** (귀무가설) : **$p_{old}$** 와 **$p_{new}$** 가 동일\n",
    ">- **$H_1$** (대립가설) : **$p_{new}$** 가 **$p_{old}$** 보다 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 - 귀무가설 $H_0$ 검정\n",
    "귀무가설 $H_0$ 하에서, $p_{new}$ 와 $p_{old}$ 는 같다고 가정한다. 또한,  $p_{new}$ 와 $p_{old}$ 는 모두 `df2` 의 **전환율**과 같다고 가정한다. 따라서, 우리의 가정은: <br><br>\n",
    "<center>\n",
    "$p_{new}$ = $p_{old}$ = $p_{population}$\n",
    "</center>\n",
    "\n",
    "이 섹션에서는: \n",
    "\n",
    "- 두 그룹 모두 샘플링(부트스트랩)을 하여, \"전환\" 확률 $p$ 를 계산한다. \n",
    "\n",
    "- 두 그룹 모두 `df2`의 데이터 개수를 샘플의 크기로 사용한다. \n",
    "\n",
    "- 위의 두 그룹의 \"전환\" 확률의 차이를 계산한다. \n",
    "\n",
    "- 두개의 표본 사이의 \"전환율 차이\"를 10,000번 반복하여 표본분포로 나타내고 예측값을 계산한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** 귀무가설 하에서 $p_{new}$의 **전환율**은 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"treatment\" 그룹의 전환율 -> 귀무가설 하에서 전체 모집단의 전환율\n",
    "p_new = df2.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** 귀무가설 하에서 $p_{old}$의 전환율은 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"control\" 그룹의 전환율 -> 귀무가설 하에서 전체 모집단의 전환율\n",
    "p_old = df2.converted.mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** treatment 그룹 사용자의 수$n_{new}$는 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"treatment\" 그룹 사용자 수\n",
    "n_new = df2[df2['landing_page']=='new_page'].shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** control 그룹 사용자의 수 $n_{old}$는 얼마인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"control\" 그룹 사용자 수\n",
    "n_old = df2[df2['landing_page']=='old_page'].shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. `treatment` 그룹의 무작위 표본 추출**<br> \n",
    "\n",
    "귀무가설 하에서, 전환율 $p_{new}$를 가지고 $n_{new}$번 무작위 추출한다. \n",
    "\n",
    "귀무가설 하에서, 전환율 $P_{new}$를 가지고 $N_{new}$번 무작위 추출하기 위해서, 우리는 아래 3가지 방법 중 하나를 사용할 수 있다:\n",
    "\n",
    "- numpy.random.binomial\n",
    "\n",
    "- numpy.random.choice\n",
    "\n",
    "- pandas.DataFrame.sample\n",
    "\n",
    "\n",
    "이 프로젝트에서는, `numpy.random.choice()` 메소드를 사용해 무작위로 $n_{new}$ 개의 값을 생성할 것이다. <br>\n",
    "그리고 이 $n_{new}$의 1과 0을 `new_page_converted` numpy 배열에 저장할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treatment 그룹의 무작위 표본 추출\n",
    "np_new = np.array(df2[df2['landing_page']=='new_page'].converted)\n",
    "new_page_converted = np.random.choice([0,1], size=n_new, p=[p_new, 1-p_new])\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. `control` 그룹의 무작위 표본 추출** <br>\n",
    "귀무가설 하에서, 전환율 $p_{old}$로 $n_{old}$번 무작위 추출한다. <br> \n",
    "그리고 이 $n_{old}$의 1과 0 값을 `old_page_converted` 라는 numpy 배열에 담는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# control 그룹의 무작위 표본 추출\n",
    "np_old = np.array(df2[df2['landing_page']=='old_page'].converted)\n",
    "old_page_converted = np.random.choice([0,1], size=n_old, p=[p_old, 1-p_old])\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g.** (e)와 (f)에서 구한 무작위 샘플의 \"전환율\" 평균의 차이를 $(p{'}_{new}$ - $p{'}_{old})$ 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002138317225620412"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 무작위 샘플의 \"전환율\" 차이\n",
    "sam_diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "sam_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**h. 표본 분포** <br>\n",
    "여기서는 위 (a) 부터 (g)까지 사용했던 무작위 추출 방법을 10,000번 반복하여 `new_page_converted` 와 `old_page_converted`를 다시 생성하고 전환율의 차이 $(p{'}_{new}$ - $p{'}_{old})$ 를 구할 것이다. \n",
    "\n",
    "<br>\n",
    "그리고 모든 전환율 차이 $(p{'}_{new}$ - $p{'}_{old})$ 값을 `p_diffs` 라고 하는 새로운 numpy 배열에 담을 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표본 분포\n",
    "p_diffs = []\n",
    "for i in range(10000):\n",
    "    new_page_converted = np.random.choice([1,0], size=n_new, p=[p_new, 1-p_new])\n",
    "    old_page_converted = np.random.choice([1,0], size=n_old, p=[p_old, 1-p_old])\n",
    "    diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "    p_diffs.append(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. 히스토그램**<br> \n",
    "**p_diffs** 의 히스토그램을 그려보자. \n",
    "\n",
    "그리고, `plt.axvline()` 메소드를 이용해 `df2` 데이터에서 관측된 실제 차이를 차트에 표시해볼 것이다. (`obs_diff`를 다시 떠올려보자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '추출 데이터 개수')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50752 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51032 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51204 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54872 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 50984 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52264 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52628 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 52636 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 45936 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 53552 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51204 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54872 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50984 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52264 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52628 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 52636 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 45936 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 53552 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 50752 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49324 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51032 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs)\n",
    "plt.axvline(x=obs_diff, color='red') # df2에서 관측된 실제 차이값\n",
    "plt.title('New_page와 Old_page 사이의 전환율 차이')\n",
    "plt.xlabel('전환율 차이')\n",
    "plt.ylabel('추출 데이터 개수')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**j.** `df2`에서 관측된 실제 차이값보다 더 큰 **p_diffs**의 비율은 얼마인가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obs_diff 보다 큰 p_diffs 비율 \n",
    "(np.array(p_diffs)>obs_diff).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과에 따라, p-value는 0.9028이라는 것을 알 수 있다. \n",
    "\n",
    "위의 히스토그램 차트를 보면, 빨간색 선에서부터 오른쪽 방향으로 많은 데이터가 있는 것을 알 수 있고(대립가설), `obs_diff`보다 큰 `p_diffs` 값이 관측될 확률인 p-value를 계산했을 때, 0.907로 이는 `제 1종 오류`의 유의수준인 0.05보다 큰 값임을 알 수 있다. 그러므로 귀무가설을 기각할 수 없고, 이는 즉 `treatment` 그룹과 `control` 그룹 사이에 전환율의 차이가 없다는 것을 가정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**l. 가설 검정을 위해 내장함수 사용하기**<br>\n",
    "내장함수를 이용해서도 비슷한 결과를 얻을 수 있다. 내장함수를 사용하는 것은 코드를 작성하기는 쉽지만, 위에서 다룬 부분은 통계적 유의성에 대해 정확하게 사고하기 위해 중요한 연습이었다는 점을 참고하자. \n",
    "\n",
    "- `convert_old`: old_page의 총 전환 횟수\n",
    "- `convert_new`: new_page의 총 전환 횟수\n",
    "- `n_old`: old_page가 주어진 사용자 수 \n",
    "- `n_new`: new_page가 주어진 사용자 수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17489, 17264, 145274, 145310)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# old_page의 총 전환 횟수\n",
    "convert_old = df2.query('landing_page == \"old_page\"').converted.sum()\n",
    "\n",
    "# new_page의 총 전환 횟수\n",
    "convert_new = df2.query('landing_page == \"new_page\"').converted.sum()\n",
    "\n",
    "# old_page가 주어진 사용자 수\n",
    "n_old = df2.query('landing_page == \"old_page\"').user_id.nunique()\n",
    "\n",
    "# new_page가 주어진 사용자 수\n",
    "n_new = df2.query('landing_page == \"new_page\"').user_id.nunique()\n",
    "\n",
    "# 확인\n",
    "convert_old, convert_new, n_old, n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**m.** 이제 `sm.stats.proportions_ztest()` 를 사용해서 검정 통계와 p-value 값을 계산하자.  \n",
    "내장함수 사용에 대해 도움을 얻고 싶다면 [여기](https://www.statsmodels.org/stable/generated/statsmodels.stats.proportion.proportions_ztest.html)를 참고해라. \n",
    "\n",
    "문법은 다음과 같다: \n",
    "```bash\n",
    "proportions_ztest(count_array, nobs_array, alternative='larger')\n",
    "```\n",
    "\n",
    "예시를 보면, 아래와 같다. \n",
    "```bash\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_new,convert_old], [n_new,n_old], alternative=\"larger\")\n",
    "```\n",
    "여기서, \n",
    "- `count_array` = 각 그룹의 \"전환율\"을 나타낸다.\n",
    "- `nobs_array` = 각 그룹의 총 관측 개수(행수)를 나타낸다.\n",
    "- `alternative` = `[‘two-sided’, ‘smaller’, ‘larger’]` 중 하나의 값을 선택한다. 차례로 양측검정, 왼쪽 단측검정, 오른쪽 단측검정을 의미한다. \n",
    "\n",
    "> 양측검정(Two-tailed) : $H_1$ 은 $(p_{new} = p_{old})$. <br>\n",
    "> 왼쪽 단측검정(Left-tailed) : $H_1$ 은 $(p_{new} < p_{old})$. <br>\n",
    "> 오른쪽 단측검정(Right-tailed) : $H_1$ 은 $(p_{new} > p_{old})$. \n",
    "\n",
    "위의 내장함수는 z_score와 p_value 값을 리턴한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이(2) 표본 Z검정 (독립표본 Z검정)\n",
    "\n",
    "앞서 10,000번 반복하여 무작위 추출된 두 개의 표본에서 \"전환율\"의 차이인 `p_diffs`, 즉 $(p{'}_{new}-p{'}_{old})$의 분포를 차트로 나타낸 것을 생각해보자. \n",
    "\n",
    "두 개의 독립 정규 분포의 평균을 비교하는 또 다른 방법은 **이(2)표본 Z검정(two-sample z-test)** 이다.   \n",
    "아래의 식을 사용해서 Z검정을 시행하고 Z_score 를 계산할 수 있다: \n",
    "\n",
    "$$\n",
    "Z_{score} = \\frac{ (p{'}_{new}-p{'}_{old}) - (p_{new}  -  p_{old})}{ \\sqrt{ \\frac{\\sigma^{2}_{new} }{n_{new}} + \\frac{\\sigma^{2}_{old} }{n_{old}}  } }\n",
    "$$\n",
    "\n",
    "여기에서,\n",
    "- $p{'}$ 는 표본의 \"전환율\" \n",
    "- $p_{new}$ 와 $p_{old}$ 는 모집단의 두 그룹의 \"전환율\" \n",
    "- $\\sigma_{new}$ 와 $\\sigma_{old}$ 는 모집단의 두 그룹의 표준편차\n",
    "- $n_{new}$ 와 $n_{old}$ 는 두 개의 그룹 또는 표본(여기서는 동일함)의 크기\n",
    "\n",
    "를 말한다. \n",
    "\n",
    ">Z검정은 표본의 크기가 크고, 모집단의 분산(또는 표준편차)를 알고 있을 때 시행한다. z-score는 표준오차에 대해서 두 개의 \"전환율\" 사이의 차이를 나타낸다.   \n",
    "> (표준오차에 대한 정보는 [여기](https://goodtogreate.tistory.com/entry/%ED%91%9C%EC%A4%80%EC%98%A4%EC%B0%A8-Standard-Error#:~:text=%ED%8F%89%EA%B7%A0%EC%9D%98%20%ED%91%9C%EC%A4%80%20%EC%98%A4%EC%B0%A8(%ED%8F%89%EA%B7%A0,%EB%82%B4%EC%9D%98%20%EB%B3%80%EB%8F%99%EC%84%B1%EC%9D%84%20%EC%B8%A1%EC%A0%95%ED%95%A9%EB%8B%88%EB%8B%A4.)에서 확인) \n",
    "\n",
    "다음 단계는 아래 두 개의 값을 비교하여 귀무가설을 기각할지 또는 채택할지 결정을 내리는 것이다: \n",
    "- $Z_{score}$\n",
    "- $Z_{\\alpha}$ 또는 $Z_{0.05}$, 또는 95%의 신뢰구간에서의 임계값.    \n",
    "단측 검정에서 $Z_{0.05}$ 는 1.645이며, 양측검정에서는 1.960이다. z-table 에서 직접 $Z_{\\alpha}$ 을 결정할 수도 있다. \n",
    "\n",
    "먼저, 가설이 양측검정인지, 왼쪽 단측검정인지, 또는 오른쪽 단측검정인지 결정할 필요가 있다. 그것에 따라서, $Z_{score}$과 $Z_{\\alpha}$를 비교해 귀무가설을 기각하거나 채택할 것이다. 다른 말로, \"기각역\"은 $Z_{score}$가 그 영역에 있을 때 귀무가설을 기각하는 구간이다. \n",
    "\n",
    ">오른쪽 단측검정의 경우, $Z_{score}$ > $Z_{\\alpha}$ 인 경우 귀무가설을 기각한다. <br>\n",
    ">왼쪽 단측검정의 경우, $Z_{score}$ < $Z_{\\alpha}$ 인 경우 귀무가설을 기각한다. \n",
    "\n",
    "\n",
    "참고: \n",
    "- 이 [페이지](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/09%3A_Two-Sample_Problems/9.01%3A_Comparison_of_Two_Population_Means-_Large_Independent_Samples)의 예시 9.1.2, courtesy www.stats.libretexts.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, statsmodels 라이브러리를 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3109241984234394 0.9050583127590245\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "z_score, p_value = sm.stats.proportions_ztest([convert_new,convert_old], [n_new,n_old], alternative=\"larger\")\n",
    "print(z_score, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z-score 가 **-1.3109**라는 것은 관측된 차이값(`obs_diff`)이 평균보다 1.31만큼 표준 편차가 낮다는 것을 의미한다. \n",
    "일반적으로, 단측 검정에서 $Z_{\\alpha}$ 또는 $Z_{0.05}$는 **1.645**이며 지금과 같이 오른쪽 단측 검정의 경우, 𝑍𝑠𝑐𝑜𝑟𝑒  >  𝑍𝛼 이면 귀무가설을 기각할 수 있다. 따라서 여기서는 𝑍𝑠𝑐𝑜𝑟𝑒 **-1.31**이 **1.645** 보다 크지 않다는 점에서, 귀무가설을 기각할 수 없다. \n",
    "\n",
    "또한 p-value는 **0.905**로 앞서 구했던 p-value인 **0.907** 과 매우 비슷한 값이다. 결과적으로 귀무가설을 기각할 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - 회귀 분석 방법\n",
    "\n",
    "###  3.1 \n",
    "이 마지막 파트에서는, 위의 PartII에서 얻은 A/B 테스트 결과가 회귀 분석 방법을 이용해 동일하게 얻어질 수 있다는 것을 확인할 것이다. <br><br> \n",
    "\n",
    "**a.** `df2` 데이터의 각 행이 \"전환\" 이거나 \"전환아님\" 둘 중 하나이기 때문에, 여기서는 **회귀분석** 방법을 이용할 것이다. \n",
    "예측된 반응변수(여기서는 `converted`)가 0과 1 사이의 확률(여기서는 _전환아님_ 이거나 _전환_)일 때 우리는 회귀 분석 방법을 사용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** 여기서 목적은 **statsmodels**  라이브러리를 사용해 사용자가 받은 페이지의 타입에 따라 전환율에 유의미한 차이가 있는지 보기 위해서 **a.**에서 말한 회귀 분석 모델을 fit하는 것이다. 그러나 먼저 아래의 두개의 컬럼을 `df2`에 생성할 필요가 있다: \n",
    " 1. `intercept` - 전체 컬럼에서 이 값은 `1`이다. \n",
    " 2. `ab_page` - 이것은 dummy 변수 컬럼으로, **treatment** 그룹인 경우 `1`을, 그렇지 않은 경우 `0`을 갖는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['intercept'] = 1\n",
    "df2['ab_page'] = pd.get_dummies(df2['group'])['treatment']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** **statsmodels** 을 사용하여 위의 (b)에서 생성한 두 개의 컬럼을 넣고 회귀 모델을 실행시키자. 그리고 사용자가 전환했는지 아닌지 예측하기 위해서 모델을 fit 해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델을 만들고 fit 해보자. \n",
    "logis_model = sm.Logit(df2['converted'], df2[['intercept','ab_page']])\n",
    "results = logis_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** 모델의 summary를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-05-30 15:35</td>       <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>        <td>LLR p-value:</td>      <td>0.18988</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212780.3502\n",
       "Date:               2022-05-30 15:35 BIC:              212801.5095\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           1                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290582           LLR p-value:      0.18988    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use summary2() method\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Part II**\n",
    "- **$H_0$** (귀무가설) : **$p_{old}$** 는 **$p_{new}$** 와 같다. \n",
    "- **$H_1$** (대립가설) : **$p_{new}$** 는 **$p_{old}$** 보다 크다.    \n",
    "\n",
    "이 경우, **단측검정** 이다.\n",
    "\n",
    "**In Part III**.  \n",
    "- **$H_0$** (귀무가설) : **$p_{old}$** 는 **$p_{new}$** 와 같다. \n",
    "- **$H_1$** (대립가설) : **$p_{old}$** 는 **$p_{new}$** 와 같지않다. \n",
    "\n",
    "이 경우, **양측검정** 이다.   \n",
    "\n",
    "또한, 여기서 p-value 값인 **0.1899**는 여전히 제 1종 오류의 유의수준인 **0.05** 보다 크다. \n",
    "\n",
    "I refered to the [Reference](https://www.statology.org/null-hypothesis-of-logistic-regression/).   \n",
    "It says,   \n",
    "\n",
    "> _\"The null hypothesis states that the coefficient(β1) is equal to zero. In other words, there is no statistically significant relationship between the predictor variable, x, and the response variable, y._   \n",
    "> _The alternative hypothesis states that coefficient(β1) is not equal to zero. In other words, there is a statistically significant relationship between x and y.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f.** Now, let's consider other things that might influence whether or not an individual converts.  I will discuss why it is a good idea to consider other factors to add into my regression model.  Are there any disadvantages to adding additional terms into my regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it seems that there is no relationship between `converted` and the `group`, we need to consider if there is other things that affects the dependent variable, `converted` along with the `group` variable.   \n",
    "\n",
    "If their combined effect on the dependent variable, which is `converted`, is ignored then the results that we get can be biased (technically known as omitted variable bias).\n",
    "\n",
    "However, including too many variables in the model can lead to a problem called Multicollinearity.   \n",
    "The more variables included in the model, typically, the less independent variation there will be for each of the individual variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**g. Adding countries**<br> \n",
    "Now along with testing if the conversion rate changes for different pages, I will also add an effect based on which country a user lives in. \n",
    "\n",
    "1. I will need to read in the **countries.csv** dataset and merge together the `df2` datasets on the appropriate rows. We call the resulting dataframe `df_merged`. [Here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) are the docs for joining tables. \n",
    "\n",
    "2. Does it appear that country had an impact on conversion?  To answer this question, I will consider the three unique values, `['UK', 'US', 'CA']`, in the `country` column. Then I will create dummy variables for these country columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the countries.csv\n",
    "df_coun = pd.read_csv('countries.csv')\n",
    "df_coun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  \n",
       "0          1        0      US  \n",
       "1          1        0      US  \n",
       "2          1        1      US  \n",
       "3          1        1      US  \n",
       "4          1        0      US  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join with the df2 dataframe\n",
    "df_merged = df2.join(df_coun.set_index('user_id'), on='user_id')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  CA  UK  US  \n",
       "0          1        0      US   0   0   1  \n",
       "1          1        0      US   0   0   1  \n",
       "2          1        1      US   0   0   1  \n",
       "3          1        1      US   0   0   1  \n",
       "4          1        0      US   0   0   1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the necessary dummy variables\n",
    "df_merged = df_merged.join(pd.get_dummies(df_merged['country']))\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212781.1253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-05-30 15:35</td>       <td>BIC:</td>        <td>212823.4439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290580</td>        <td>LLR p-value:</td>      <td>0.17599</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0300</td>  <td>0.0266</td>  <td>-76.2488</td> <td>0.0000</td> <td>-2.0822</td> <td>-1.9778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0149</td>  <td>0.0114</td>   <td>-1.3069</td> <td>0.1912</td> <td>-0.0374</td> <td>0.0075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>0.0408</td>   <td>0.0269</td>   <td>1.5161</td>  <td>0.1295</td> <td>-0.0119</td> <td>0.0934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0506</td>   <td>0.0284</td>   <td>1.7835</td>  <td>0.0745</td> <td>-0.0050</td> <td>0.1063</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212781.1253\n",
       "Date:               2022-05-30 15:35 BIC:              212823.4439\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           3                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290580           LLR p-value:      0.17599    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0300    0.0266  -76.2488  0.0000  -2.0822  -1.9778\n",
       "ab_page       -0.0149    0.0114   -1.3069  0.1912  -0.0374   0.0075\n",
       "US             0.0408    0.0269    1.5161  0.1295  -0.0119   0.0934\n",
       "UK             0.0506    0.0284    1.7835  0.0745  -0.0050   0.1063\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model, and summarize the results\n",
    "country_model = sm.Logit(df_merged['converted'], df_merged[['intercept', 'ab_page', 'US', 'UK']])\n",
    "country_result = country_model.fit()\n",
    "country_result.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.131332\n",
       "ab_page      0.985168\n",
       "US           1.041599\n",
       "UK           1.051944\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponentiate the coefficents from the summary \n",
    "np.exp(country_result.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all p-values in the summary, all the p-values are **greater** than the _Type I Error rate_ of 0.05.     \n",
    "So I can conclude that this logistic model is **NOT statistically significant** and there is no relationship between conversion rate and country either.   \n",
    "\n",
    "With coefficient values above, I can add\n",
    "\n",
    "- For every unit for UK user, conversion is 1% more likely to happen compared to CA user, holding all other variables constant.    \n",
    "- For every unit for US user, conversion is 1% more likely to happen compared to CA user, holding all other variables constant.     \n",
    "\n",
    "But these findings are not practically significant as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h. Fit the model and obtain the results**<br> \n",
    "Though we have now looked at the individual factors of country and page on conversion, we would now like to look at an **interaction between page and country** to see if there are significant effects on conversion.  \n",
    "\n",
    "First, I will create the necessary additional columns for interactive dummy variables, and fit the new model.   \n",
    "These are simply created by multiplying the country and treatment dummy variables - for each country -.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>country</th>\n",
       "      <th>CA</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>US-inter</th>\n",
       "      <th>UK-inter</th>\n",
       "      <th>CA-inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page country  CA  UK  US  US-inter  UK-inter  CA-inter  \n",
       "0          1        0      US   0   0   1         0         0         0  \n",
       "1          1        0      US   0   0   1         0         0         0  \n",
       "2          1        1      US   0   0   1         1         0         0  \n",
       "3          1        1      US   0   0   1         1         0         0  \n",
       "4          1        0      US   0   0   1         0         0         0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add interactive dummy variables. \n",
    "df_merged['US-inter'] = df_merged['US']*df_merged['ab_page']\n",
    "df_merged['UK-inter'] = df_merged['UK']*df_merged['ab_page']\n",
    "df_merged['CA-inter'] = df_merged['CA']*df_merged['ab_page']\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>          <td>AIC:</td>        <td>212782.6602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2022-05-30 15:35</td>       <td>BIC:</td>        <td>212846.1381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>       <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>            <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290578</td>        <td>LLR p-value:</td>      <td>0.19199</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0040</td>  <td>0.0364</td>  <td>-55.0077</td> <td>0.0000</td> <td>-2.0754</td> <td>-1.9326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0674</td>  <td>0.0520</td>   <td>-1.2967</td> <td>0.1947</td> <td>-0.1694</td> <td>0.0345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>0.0175</td>   <td>0.0377</td>   <td>0.4652</td>  <td>0.6418</td> <td>-0.0563</td> <td>0.0914</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0118</td>   <td>0.0398</td>   <td>0.2957</td>  <td>0.7674</td> <td>-0.0663</td> <td>0.0899</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US-inter</th>  <td>0.0469</td>   <td>0.0538</td>   <td>0.8718</td>  <td>0.3833</td> <td>-0.0585</td> <td>0.1523</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK-inter</th>  <td>0.0783</td>   <td>0.0568</td>   <td>1.3783</td>  <td>0.1681</td> <td>-0.0330</td> <td>0.1896</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.000      \n",
       "Dependent Variable: converted        AIC:              212782.6602\n",
       "Date:               2022-05-30 15:35 BIC:              212846.1381\n",
       "No. Observations:   290584           Log-Likelihood:   -1.0639e+05\n",
       "Df Model:           5                LL-Null:          -1.0639e+05\n",
       "Df Residuals:       290578           LLR p-value:      0.19199    \n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "No. Iterations:     6.0000                                        \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0040    0.0364  -55.0077  0.0000  -2.0754  -1.9326\n",
       "ab_page       -0.0674    0.0520   -1.2967  0.1947  -0.1694   0.0345\n",
       "US             0.0175    0.0377    0.4652  0.6418  -0.0563   0.0914\n",
       "UK             0.0118    0.0398    0.2957  0.7674  -0.0663   0.0899\n",
       "US-inter       0.0469    0.0538    0.8718  0.3833  -0.0585   0.1523\n",
       "UK-inter       0.0783    0.0568    1.3783  0.1681  -0.0330   0.1896\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model, and summarize the results\n",
    "country_inter_model = sm.Logit(df_merged['converted'], df_merged[['intercept', 'ab_page', 'US', 'UK', 'US-inter', 'UK-inter']])\n",
    "country_inter_results = country_inter_model.fit()\n",
    "country_inter_results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.134794\n",
       "ab_page      0.934776\n",
       "US           1.017682\n",
       "UK           1.011854\n",
       "US-inter     1.048001\n",
       "UK-inter     1.081428\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponentiate the coefficents from the summary \n",
    "np.exp(country_inter_results.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at all p-values in the summary, all the p-values here are also **greater** than the _Type I Error rate_ of 0.05.**   \n",
    "So I can conclude that this logistic model is also **NOT statistically significant** and there is no interaction between page and country, and conversion rate and page+country as well.   \n",
    "\n",
    "With coefficient values above, I can add\n",
    "\n",
    "- For every unit for UK user + new page, conversion is 1% more likely to happen compared to CA user, holding all other variables constant.    \n",
    "- For every unit for US user + new page, conversion is 1% more likely to happen compared to CA user, holding all other variables constant.     \n",
    "\n",
    "But these findings are not practically significant as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, through the sampling distributions and logistic regression models, I could **NOT** find any clues to reject the null hypothesis. \n",
    "In all of the analysis in each steps, p-value was greater than the _Type I Error rate_ of 0.05, assuming that the results are likely from the null hypothesis.  \n",
    "\n",
    "Also, in logistic regression model, I added additional information about `countries` in order to find any relationship with the dependent variable, `converted`. However, there was no evidence that the `countries` data itself and the combined variable `countries` plus `ab_page` were related to the conversion rate.   \n",
    "\n",
    "So, in conclusion I **failed to reject the null hypothesis.**  \n",
    "\n",
    "I can say that the **new page is NOT better than the old page**, so it is better to keep the version A instead of B.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='submission'></a>\n",
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb)\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place, \n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document. \n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the \n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    overwrite base name use for output files.\n",
      "                can only be used when converting one notebook at a time.\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current \n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy \n",
      "            of reveal.js. \n",
      "            For speaker notes to work, this must be a relative path to a local \n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
      "            can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of \n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'Analyze_ab_test_results_notebook.ipynb' matched no files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the notebook to the .html file. \n",
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
