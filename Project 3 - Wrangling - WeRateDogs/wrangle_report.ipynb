{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objectives of the project were: \n",
    "\n",
    "   - Gather data from different sources (*csv file*, *tsv file*, *tweepy API*).  \n",
    "   - Store and assess data for finding any quality & tidiness issues.\n",
    "   - Clean the data using various methods in pandas.\n",
    "   - Analyze and visualize the cleaned data. \n",
    "   - Reporting on 1) data wrangling efforts and 2) data analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I worked on the following 3 datasets. \n",
    "\n",
    "1. **The WeRateDogs Twitter archive** <br>\n",
    "Manually download the CSV file - 'twitter-archiveenhanced.csv' <br><br>\n",
    "\n",
    "2. **Image Predictions File**   <br> \n",
    "Programmatically downloaded from provided Udacity Server Url using Requests library. <br><br>\n",
    "\n",
    "3. **Additional Data via the Twitter API** <br> \n",
    "Used Tweepy Library and the Twitter API for writing json data to a file called tweet_json.txt\n",
    "Each tweet's JSON data was written to its own line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assessing and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I addressed the issues arised from data assessment and cleaning process in below tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    table {\n",
    "        display: inline-block\n",
    "    }\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "    \n",
    "|<div style=\"width:50px\">No.</div>|<div style=\"width:300px\">Assessment</div>|<div style=\"width:300px\">Cleaning</div>|\n",
    "|--------|:------------------------------|:------------------------------|\n",
    "|  1. |We only need original tweets with dog images. So retweets, replies need to be deleted from the `df_archive`. <br /> Also any rows without a dog image need to be deleted from the `df_image`. <br /> Then only include rows in `df_archive` which are existed in `df_image` table based on the *tweet_id*.|Exclude retweet & reply rows from `archive`. <br />Only include rows with dog image. <br /> Exclude rows with all False values in *p1_dogs*, *p2_dogs*, *p3_dogs* columns from `image`. <br /> Then use **`isin()`** method to filter only rows with tweet_id in `image`.|\n",
    "|  2. |Rating numerator and rating denominater have null / 0 values. | Find rows with null or 0 in *rating_numerator* and *rating_denominator* columns and drop the rows using **`drop()`** method.|\n",
    "|  3. |Wrong rating numerator and rating denominator values which include decimal points. |Extract rating numerator and denominator values including decimal points from *text* column using **`extract()`** and round the newly extracted value to integer and update the wrong data. |\n",
    "|  4. | Rating numerator should not be less than 10. And rating denominator should be 10.| For rating numerator, 10 needs to be added to any values smaller than 10 using **`lambda`** function. <br />  Rating denominator should be equal to 10. Any value that is not equal to 10 needs to be revised. |\n",
    "|  5. |Missing or invalid *names*. (some of values written as \"None\", \"Not\", \"a\", \"such\", \"NaN\", etc.) |Convert those values into NaN using **`.loc`** and **`np.nan`**|\n",
    "|  6. | Wrong data types for tweet_id (need to be converted to object from int) | Convert datatype of *tweet_id* column using **`astype(str)`** method. |\n",
    "|  7. | Wrong data types (*timestamp* column should be converted to datetime from object in `df_archive`, `df_selected`)| As `df_selected` dataset was merged into `df_archive`, only convert data type of *timestamp* column in `df_archive` using **`pd.to_datetime()`** method. \n",
    "|  8. | Wrong data types (*p1_dog*, *p2_dog*, *p3_dog* columns should be converted to category from object in `df_image`)| Convert the data type using **`.astype('category')`**. \n",
    "|  9. | In some rows, the last part of the *expanded_urls* which indicates tweet id was not the same value with *tweet_id*.| After excluding retweets & replies from the dataset, rows having different *expanded_urls* from the *tweet_id* were disappeared. |\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "    \n",
    "|<div style=\"width:50px\">No.</div>|<div style=\"width:300px\">Assessment</div>|<div style=\"width:300px\">Cleaning</div>|\n",
    "|-----|:------------------------------|:------------------------------|\n",
    "|  1. | Colums for dog stages in `df_archive` are divided into 4 columns - *doggo*, *floofer*, *pupper*, *puppo*. <br /> They can be merged into one column 'dog stage' and the each column headers should be values in the 'dog stage' column. | Merge doggo, floofer, pupper, puppo columns to a 'dog_stage' column according to the following steps. <br /> 1) Set the None values to np.nan in all the 4 dog stage columns. <br /> 2) Concatenate all 4 columns to 1 column dog_stage. For multiple values, add comma(,) like `doggo, pupper`. <br /> 3) Remove the original 4 columns of dog stages. | \n",
    "|  2. |`df_selected` and `df_archive` can be merged into one table as both contains information about tweet archives.| Merge df_selected and df_archive using **`.merge()`** method. |\n",
    "|  3. | After deleting rows that are retweets or replies from `df_archive`, we don't need related 5 columns anynore. <br />   *in_reply_to_status_id*, *in_reply_to_user_id*, *retweeted_status_id*, <br /> *retweeted_status_user_id*, *retweeted_status_timestamp* | Drop 5 columns from `df_archive` using **`.drop()`** method. | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
